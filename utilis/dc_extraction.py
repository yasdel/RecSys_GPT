# -*- coding: utf-8 -*-
"""DC_Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tjdk1wW7nVHSsi5L_Zjgg0jgSLendD4m
"""
import numpy as np
import pandas as pd

# from https://github.com/oliviaguest/gini/blob/master/gini.py
def gini(array):
  '''
  Calculate the Gini coefficient of a numpy array, according to formula http://www.statsdirect.com/help/generatedimages/equations/equation154.svg
  from http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm
  Taken the input array:
  - cast values to float
  - shift them so that they are positive
  - ensure there is not any 0
  - sort values
  - compute Gini index

  Examples
  ---------
  gini(np.array([.2,.2,.2,.2,.2,0])) = 0.1666
  gini(np.array([1,0,0,0,0,0])) = 0.8333

  '''
  # All values are treated equally, arrays must be 1d:
  array = array.flatten()
  array = array.astype(np.float64)
  if np.amin(array) < 0:
      # Values cannot be negative:
      array -= np.amin(array)
  # Values cannot be 0:
  array += 0.0000001
  # Values must be sorted:
  array = np.sort(array)
  # Index per array element:
  index = np.arange(1,array.shape[0]+1)
  # Number of array elements:
  n = array.shape[0]
  # Gini coefficient:
  return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))


def gini_user_item(df):
  '''
  Compute Gini coefficient as a measure of inequality in the distribution 
  of interactions across items ('gini_item'), and across users ('gini_user')

  Notes
  --------
  Potential shortcomings for Gini index (in general):
  - it does not tell the shape of inequality across distribution,
    considering geometric interpretation of 2*(area between equality diagonal and Lorenz curve),
    thus very different distributions can result in identical Gini coefficients
  - it does not show variations among subgroups within the distribution
    e.g. the distribution of interactions across user mainstreaminess, gender (if known)

  '''
  interactions_per_user = df.userId.value_counts(normalize=True).to_numpy()
  interactions_per_item = df.itemId.value_counts(normalize=True).to_numpy()
  gini_user = gini(interactions_per_user)
  gini_item = gini(interactions_per_item)

  return gini_user, gini_item


def log_density(noUsers, noItems, noRatings):
  log_density = np.log10(noRatings/(noUsers * noItems))
  return log_density


def log_shape(noUsers, noItems):
  log_shape = np.log10(noUsers / noItems)
  return log_shape


def popularity_segment_flexibleGroup(ratings_df, proportion_list):
  '''
  Inputs
  ----------
    - ratings_df: a UIR dataframe in the form (userId, itemId, rating)
    - proportion_list: a list of proportions i.e., values within [0,1] indicating the proportion of interactions belonging to each item class label (e.g. short-head, distant-tail).

  Outputs
  ----------
    - ratings_df_res: the input dataframe with a new column i.e., a class label
      showing if each item belongs to 'short-head'(0), 'mid-tail'(1), 'distant-tail'(2) class.

    - items_df: a dataframe in the form (item, popClass)

    - itemIds: list of ids of short-head, mid-tail, and distant tail items
  
  Usage (*dataset needed*)
  ----------
  popularity_segment_flexibleGroup(toy_df, [0.8,0.2])

  '''
  if sum(proportion_list) != 1: 
    raise ValueError('Proportions in `proportion_list` parameter should sum to 1!')
  # produces the count matrix for items
  items_df = ratings_df[['userId', 'itemId', 'rating']].groupby('itemId') \
                                .size() \
                                .reset_index(name='count') \
                                .sort_values(['count'], ascending=False)
  # define the thresholds for popularity classes
  tmp = items_df.copy()
  nInt = tmp['count'].sum()
  shortThr = np.rint(proportion_list[0] * nInt)
  if len(proportion_list) == 3:
    midThr = np.rint(proportion_list[1] * nInt) + shortThr
  else:
    midThr = None
  # divide items into short_head, mid_tail (and distant_tail, if specified in the 'proportion_list' parameter)
  tmp['CDF'] = tmp['count'].cumsum()

  short_head = tmp.loc[tmp['CDF'].lt(shortThr),'itemId']
  if midThr is not None:
    mid_tail = tmp.loc[tmp['CDF'].lt(midThr) & ~tmp['itemId'].isin(short_head),'itemId']
    distant_tail = tmp.loc[~(tmp['itemId'].isin(mid_tail) | tmp['itemId'].isin(short_head)),'itemId']
    conditions = [items_df['itemId'].isin(short_head), items_df['itemId'].isin(mid_tail), items_df['itemId'].isin(distant_tail)]
    choices = [0, 1, 2]
    items_df['popClass'] = np.select(conditions, choices, default=2)
  else:
    distant_tail = tmp.loc[~tmp['itemId'].isin(short_head),'itemId']
    items_df['popClass'] = np.where(items_df['itemId'].isin(short_head), 0, 1)

  ratings_df_res = ratings_df.merge(items_df, on='itemId')

  # build itemIds
  itemIdsShort = items_df[items_df['popClass'] == 0].sort_values('count')['itemId'].tolist()
  itemIdsMid = items_df[items_df['popClass'] == 1].sort_values('count')['itemId'].tolist()
  itemIdsDistant = items_df[items_df['popClass'] == 2].sort_values('count')['itemId'].tolist()
  itemIds = [itemIdsShort, itemIdsMid, itemIdsDistant]

  return ratings_df_res, items_df, itemIds


def popularity_bias(ratings_df, proportion_list, verbose=False):
  '''
  Inputs
  ----------
    - ratings_df: a UIR dataframe in the form (userId, itemId, rating)
    - proportion_list: a list of proportions i.e., values within [0,1] indicating the proportion of interactions belonging to each item class label (e.g. short-head, distant-tail).

  Outputs
  ----------
    - pop_bias: Popularity bias, computed as the ratio between average interactions of popular items (lowest popClass label) and avg interactions of niche items (highest popClass label)

    - ratings_df_res: the input dataframe with a new column i.e., a class label
      showing if each item belongs to 'short-head'(0), 'mid-tail'(1), 'distant-tail'(2) class.

    - items_df: a dataframe in the form (item, popClass)

    - itemIds: list of ids of short-head, mid-tail, and distant tail items
  
  Usage (*dataset needed*)
  ----------
  popularity_bias(toy_df, [0.8,0.2], verbose=True)

  '''

  if sum(proportion_list) != 1: 
    raise ValueError('Proportions in `proportion_list` parameter should sum to 1!')
  ratings_df_res, items_df, itemIds = popularity_segment_flexibleGroup(ratings_df, proportion_list)
  noRatingShort = (ratings_df_res['popClass'] == 0).sum()
  noRatingMid = (ratings_df_res['popClass'] == 1).sum()
  noRatingDistant = (ratings_df_res['popClass'] == 2).sum()
  noShort = (items_df['popClass'] == 0).sum()
  noMid = (items_df['popClass'] == 1).sum()
  noDistant = (items_df['popClass'] == 2).sum()
  r_i_ratio_head = noRatingShort/noShort
  r_i_ratio_tail = noRatingDistant/noDistant if noDistant!=0 else noRatingMid/noMid
  pop_bias = r_i_ratio_head / r_i_ratio_tail

  if verbose:
    print(f'''
    ----------------------------------
    Number of Ratings collected by short-head items: {noRatingShort})
    Number of Ratings collected by mid-tail items: {noRatingMid})
    Number of Ratings collected by distant-tail items: {noRatingDistant})
    Number of short-head items: {noShort})
    Number of mid-tail items: {noMid})
    Number of distant-tail items: {noDistant})
    # R/I (short-head items): {noRatingShort/noShort})
    # R/I (mid-tail items): {noRatingMid/noMid})
    # R/I (distant-tail items): {noRatingDistant/noDistant})
    ----------------------------------
    ''')

  return pop_bias, ratings_df_res, items_df, itemIds


def user_mainstreaminess(ratings_df, mainstr_thres=0, return_flag_col=False):
  '''
  Inputs
  ----------
    - ratings_df: a UIR dataframe in the form (userId, itemId, rating)
    - mainstr_thres: 
        A threshold used to determine which users are considered 'mainstream' i.e. have preferred popular items in observed interactions.
        Specifically, this threshold is used with a 'mainstreaminess_score' (see output below for further details on this score).

  Outputs
  ----------
    - df_w_mainstr_info: input dataset enriched with user mainstreaminess info (items are ignored here). Specifically, info is detailed in 3 columns:
        1. 'historical popularity affinity': list with proportion of user interactions with popular and unpopular items, respectively. 
                                             Note that ratio between these two elements gives 'mainstreaminess score'
        2. 'mainstreaminess score': numerical score based on user history, defined as the ratio between proportions of popular and unpopular items she has interacted with. 
                                    If denominator is 0 (user has not interacted with any non-popular item), this score is set to 1e5
        3. (if return_flag_col=False) 'is_mainstream': boolean flag indicating whether the user has been classified as mainstream or not.
    - (if return_flag_col=True) flag_col: a Series with a boolean flag for each user, indicating whether the user has been classified as mainstream or not.

  Usage (*dataset needed*)
  ----------
  df, flag_col = user_mainstreaminess(toy_df, mainstr_thres=3, return_flag_col=True) # or use FairnessEval.MAINSTR_THRES as mainstr_thres

  '''

  ratings_df_res, items_df, itemIds = popularity_segment_flexibleGroup(ratings_df, [0.8,0.2])
  # group by user and count items with popClass == i (0 is short-head, 2 is distant tail)
  hist_pop_affinity = pd.crosstab(index=ratings_df_res['userId'], columns=ratings_df_res['popClass'], normalize='index')

  lst, mainstr_scores = [], []
  hist_pop_affinity.columns = hist_pop_affinity.columns.astype(str)
  for a, b in zip(hist_pop_affinity['0'], hist_pop_affinity['1']):
    lst.append([a,b])
    mainstr_scores.append(a/b if b != 0 else 100000)
  hist_pop_affinity.loc[:,'historical popularity affinity'] = [str(x) for x in lst]
  hist_pop_affinity.loc[:,'mainstreaminess score'] = mainstr_scores
  hist_pop_affinity.loc[:,'is_mainstream'] = hist_pop_affinity['mainstreaminess score'] >= mainstr_thres
  hist_pop_affinity.drop(columns=['0','1'], inplace=True)
  df_w_mainstr_info = ratings_df.join(hist_pop_affinity, on='userId', how='left')
  df_w_mainstr_info = df_w_mainstr_info[['userId','historical popularity affinity','mainstreaminess score','is_mainstream']].drop_duplicates()
  df_w_mainstr_info = df_w_mainstr_info.set_index('userId')

  if return_flag_col: return df_w_mainstr_info.drop(columns=['is_mainstream']), df_w_mainstr_info['is_mainstream']
  return df_w_mainstr_info


def user_activity(df_ratings, proportion_list, return_flag_col=False):
  '''
  Inputs
  ----------
    - ratings_df: a UIR dataframe in the form (userId, itemId, rating)
    - proportion_list: a list of proportions i.e., values within [0,1] and summing to 1, 
                       where each value 'i' indicates the proportion of cumulative interactions of users with i-th class label out of total interactions. 
                       For example, '[0.8,0.2]' indicates that 80% of interactions will belong to users with class label '0' (i.e., active users). 

  Outputs
  ----------
    - df_w_activ_info: input dataset enriched with user activity info (items are ignored here). Specifically, info is detailed in 2 columns:
        1. 'activity score': numerical score defined as the ratio between observed interactions for a single user and total interactions in df_ratings. 
        2. (if return_flag_col=False) 'is_active': boolean flag indicating whether the user has been classified as active or not.
    - (if return_flag_col=True) flag_col: a Series with a boolean flag for each user, indicating whether the user has been classified as active or not.

  Usage (*dataset needed*)
  ----------
  df, flag_col = user_activity(toy_df, proportion_list=[0.8,0.2], return_flag_col=True) # or use FairnessEval.ACTIV_PROPORTIONS as proportion_list

  '''

  activity_df = df_ratings[['userId', 'itemId', 'rating']].groupby('userId')  \
                                                  .size()  \
                                                  .reset_index(name='count')  \
                                                  .sort_values(['count'], ascending=False)
  tot_int = activity_df['count'].sum()
  # Compute some activity score for each user: number of interactions as percentage of total
  activity_df.loc[:,'activity score'] = [x/tot_int for x in activity_df['count']]
  # Divide users into active and non-active, according to the proportion of total interactions from 'proportion_list' parameter
  activity_df.loc[:,'CDF'] = activity_df['count'].cumsum()
  # Threshold for activity class
  thres = np.rint(proportion_list[0] * tot_int)
  activity_df.loc[:,'is_active'] = activity_df['CDF'] < thres
  df_w_activ_info = df_ratings.merge(activity_df, on='userId')
  df_w_activ_info = df_w_activ_info[['userId','is_active','activity score']].drop_duplicates()
  df_w_activ_info = df_w_activ_info.set_index('userId')

  if return_flag_col: return df_w_activ_info.drop(columns=['is_active']), df_w_activ_info['is_active']
  return df_w_activ_info


def item_popularity(ratings_df, proportion_list, return_flag_col=False):
  '''
  Inputs
  ----------
    - ratings_df: a UIR dataframe in the form (userId, itemId, rating)
    - proportion_list: a list of proportions i.e., values within [0,1] and summing to 1, 
                       where each value 'i' indicates the proportion of cumulative interactions of items with class label 'i' out of total interactions. 
                       For example, '[0.8,0.2]' indicates that 80% of interactions will belong to items with class label '0' (i.e., popular items, aka 'short-head'). 

  Outputs
  ----------
    - df_w_pop_info: input dataset enriched with item popularity info (users are ignored here). Specifically, info is detailed in 2 columns:
        1. 'popularity score': numerical score defined as the ratio between observed interactions for a single item and total interactions in df_ratings. 
        2. (if return_flag_col=False) 'is_popular': boolean flag indicating whether the item has been classified as popular or not.
    - (if return_flag_col=True) flag_col: a Series with a boolean flag for each item, indicating whether the item has been classified as popular or not.

  Usage (*dataset needed*)
  ----------
  df, flag_col = item_popularity(toy_df, proportion_list=[0.8,0.2], return_flag_col=True) # or use FairnessEval.POP_PROPORTIONS as proportion_list

  Technical notes
  ----------
  Similar steps as for user activity (because they are both based on number of interactions)
  '''
  pop_df = ratings_df[['userId', 'itemId', 'rating']].groupby('itemId')  \
                                                  .size()  \
                                                  .reset_index(name='count')  \
                                                  .sort_values(['count'], ascending=False)
  tot_int = pop_df['count'].sum()
  # compute some popularity score for each item: number of interactions as percentage of total
  pop_df['popularity score'] = [x/tot_int for x in pop_df['count']]
  # divide users into active and non-active, according to the proportion of total interactions from 'proportion_list' parameter
  pop_df['CDF'] = pop_df['count'].cumsum()
  # Threshold for popularity class
  thres = np.rint(proportion_list[0] * tot_int)
  # create new column acting as class label, where True is non-popular and False is popular
  pop_df['is_popular'] = pop_df['CDF'] < thres
  # Add item popularity info to input dataframe
  df_w_pop_info = ratings_df.merge(pop_df, on='itemId')
  df_w_pop_info = df_w_pop_info[['itemId','is_popular','popularity score']].drop_duplicates()
  df_w_pop_info.loc[:,'itemId'] = df_w_pop_info['itemId'].astype(str)
  df_w_pop_info = df_w_pop_info.set_index('itemId')

  if return_flag_col: return df_w_pop_info.drop(columns=['is_popular']), df_w_pop_info['is_popular']
  return df_w_pop_info
